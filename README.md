Identifying the optimal model for a machine learning problem requires many steps.  Not only is one faced with the choice between several potential classes of models but also one is faced with choosing between several different versions of a model (i.e. hyper-parameter tuning) which can be costly in terms of time to execute. The process is complicated a bit for models relying on time-series data since the conventional methods of validation (i.e. cross-validation) do not maintain the temporal order of the data.  In this analysis, we demonstrate an efficient and cost-effective framework for model selection that addresses these issues.  We will use the scikit-learn Pipeline Class to parsimonously train, validate and test several models with the aim of building a trading strategy to predict the direction of USDCAD.  The trading strategy will take a long unit position if the model predicts an upwards directional price movement and a short unit position if the model predicts a downwards directional price movement.  To aid the models we will transform the features so that they are stationary.  Stationary data possess beneficial mean-reverting properties which can make it easier for models to ingest.  To overcome the problems of cross-validation, we will rely upon time-series cross-validation. We will begin by looking at Logistic Regression which is one of the simpler binary classifiers and compare it against more complex models such as Support Vector Machines (SVMs) and Multi-Layer Perceptrons (MLPs).  Finally we examine whether an ensemble model, Gradient Boosting Classifier (GBC), which combines multiple decision trees to create a more powerful model, can outperform the simpler models.  